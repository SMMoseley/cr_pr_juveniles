{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3aae394-a139-4d6d-adde-1f1d415c8858",
   "metadata": {},
   "source": [
    "This notebook is used to generate some example plots used in Figure 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6a0dbc-320d-41ce-8560-b9bd228c3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb506cdf-56bb-407c-bc6b-d61e0e09fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env NBANK_REGISTRY https://gracula.psyc.virginia.edu/neurobank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86165be1-3ace-4dc2-9b2f-32c17e3e274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import ewave\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "from dlab import pprox, nbank, spikes, plotting, signal\n",
    "\n",
    "import graphics_defaults\n",
    "from core import MotifSplitter, split_trials, trial_to_spike_train, pairwise_spike_comparison\n",
    "\n",
    "rng = default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93feea1f-73de-494f-9a80-e02937a43c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_binwidth = 0.005\n",
    "rate_bandwidth = 0.02\n",
    "kernel, _ = signal.kernel(\"gaussian\", rate_bandwidth, rate_binwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5959dc4-b1ad-4fbf-a597-8e230959f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weakly selective\n",
    "unit_name = \"C104_3_1_c67\"\n",
    "selected_motifs = [\"g29wxi4q\", \"vekibwgj\", \"jkexyrd5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56deec8-7cf2-4170-a17b-f55e8fe9110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selective\n",
    "unit_name = \"C42_4_1_c131\"\n",
    "selected_motifs = [\"g29wxi4q\", \"vekibwgj\", \"ztqee46x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1bc30-2270-423f-8f60-be2cc3db2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high firing rate, temporal patterning, quite invariant\n",
    "unit_name = \"C104_4_1_c120\"\n",
    "selected_motifs = [\"g29wxi4q\", \"vekibwgj\", \"ztqee46x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48dd97-c2a1-474e-8b49-6844acd20cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprox_file = nbank.find_resource(unit_name)\n",
    "unit = json.loads(pprox_file.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8f955-a528-46f7-a15f-9a794f605aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = MotifSplitter()\n",
    "motifs = split_trials(splitter, unit).drop(\"igmi8fxa\", level=1)\n",
    "motif_names = motifs.index.unique(level=\"foreground\")\n",
    "wav_signals = {}\n",
    "for name, location in nbank.find_resources(*motif_names):\n",
    "    with ewave.wavfile(location, \"r\") as fp:\n",
    "        wav_signals[name] = (fp.read(), fp.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0e3d1-b4cf-4b8a-9c94-32533a1c3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_motifs = len(selected_motifs)\n",
    "# plot each noise level in a different color\n",
    "colors = {\n",
    "    v: c for v, c in zip(motifs.index.unique(level=0), plt.color_sequences[\"tab20\"])\n",
    "}\n",
    "fig = plt.figure(figsize=(2.4, 2.9), dpi=300)\n",
    "subfigs = fig.subfigures(1, n_motifs, hspace=0.001, wspace=0.0001)\n",
    "for motif, subfig in zip(selected_motifs, subfigs):\n",
    "    trials = motifs.xs(motif, level=\"foreground\")\n",
    "    axes = subfig.subplots(3, sharex=True, height_ratios=[1, 5, 1])\n",
    "    plotting.spectrogram(axes[0], frequency_range=(0, 8000), *wav_signals[motif])\n",
    "    axes[0].set_yticks([500, 8000], [\"1\", \"8\"])\n",
    "    for i, trial in enumerate(trials.sort_index(ascending=False).itertuples()):\n",
    "        if isinstance(trial.events, float):\n",
    "            continue\n",
    "        background_level = trial.Index\n",
    "        axes[1].plot(\n",
    "            trial.events,\n",
    "            [i] * trial.events.size,\n",
    "            color=colors[background_level],\n",
    "            marker=\"|\",\n",
    "            markeredgewidth=0.5,\n",
    "            linestyle=\"\",\n",
    "        )\n",
    "    axes[1].set_ylim(0, trials.shape[0])\n",
    "    axes[1].get_yaxis().set_visible(False)\n",
    "    plotting.adjust_raster_ticks(axes[1], gap=3.2)\n",
    "    for lvl, trls in trials.sort_index(ascending=False).groupby(\"background-dBFS\"):\n",
    "        rate, bins = spikes.rate(\n",
    "            trls.events.dropna().explode(),\n",
    "            rate_binwidth,\n",
    "            kernel,\n",
    "            start=0,\n",
    "            stop=trials.interval_end.max(),\n",
    "        )\n",
    "        axes[2].plot(bins, rate, color=colors[lvl])\n",
    "    plotting.simple_axes(*axes)\n",
    "    #subfig.subplots_adjust(hspace=0.01)\n",
    "\n",
    "max_rate = max(subfig.axes[2].get_ylim()[1] for subfig in subfigs.flat)\n",
    "for subfig in subfigs:\n",
    "    subfig.axes[2].set_ylim((0, max_rate))\n",
    "    subfig.subplots_adjust(left=0.05, right=0.95, hspace=0.08)\n",
    "for subfig in subfigs[1:]:\n",
    "    for ax in subfig.axes:\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.spines[\"left\"].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec75b6-438d-4aeb-bed5-c7cef571eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{unit_name}_motif_rasters.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426a27f-0b00-4746-950e-7d474908eea4",
   "metadata": {},
   "source": [
    "## Motif discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e781cd-c6e5-4a52-b497-09896bfc821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspike\n",
    "\n",
    "def inv_spike_sync_matrix(*args, **kwargs):\n",
    "    return 1 - pyspike.spike_sync_matrix(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa5fa8-0f7a-4006-b6e9-05f43abed3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_validate, LeaveOneOut, cross_val_score, cross_val_predict\n",
    "\n",
    "n_neighbors = 9\n",
    "\n",
    "class ShuffledLeaveOneOut(LeaveOneOut):\n",
    "    \n",
    "    def __init__(self, rng):\n",
    "        super().__init__()\n",
    "        self.rng = rng\n",
    "        \n",
    "    def split(self, *args, **kwargs):\n",
    "        for train, test in super().split(*args, **kwargs):\n",
    "            yield self.rng.permutation(train), test\n",
    "            \n",
    "def kneighbors_classifier(distance_matrix, rng, normalize=\"true\"):\n",
    "    \"\"\"Compute confusion matrix of a k-neighbors classifier on the spike distance matrix\"\"\"\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=\"precomputed\")\n",
    "    loo = ShuffledLeaveOneOut(rng)\n",
    "    groups = distance_matrix.index\n",
    "    names = groups.unique()\n",
    "    group_idx, _ = pd.factorize(groups)\n",
    "    cv_results = cross_val_score(neigh, distance_matrix.values, group_idx, cv=loo)\n",
    "    pred = cross_val_predict(neigh, distance_matrix.values, group_idx, cv=loo)\n",
    "    cm = confusion_matrix(group_idx, pred, normalize=normalize)\n",
    "    return pd.DataFrame(cm, index=names, columns=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3face-5f04-4e31-9241-e3976167432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_trains = motifs.apply(\n",
    "    partial(trial_to_spike_train, interval_end=motifs.interval_end.min()), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3fc0b2-d92a-4c96-b16c-52d37246bd09",
   "metadata": {},
   "source": [
    "These are the spike distance matrixes for training. Only the bottom one is used in the paper, because we use the testing distance matrices (comparing responses to noisy stimuli against the responses to clean stimuli) for the 30 dB and -10 dB levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a3c02-40c3-4751-b796-61e1077a8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkgnd_levels = (-25, -100)\n",
    "figsize_distances = (1.5, 2.5)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=figsize_distances, dpi=400)\n",
    "for ax, bkgnd_level in zip(axes, bkgnd_levels):\n",
    "    st = spike_trains.loc[bkgnd_level]\n",
    "    dist = inv_spike_sync_matrix(st)\n",
    "    img = ax.imshow(1 - dist, vmin=0, vmax=1, aspect=\"equal\", origin=\"upper\", interpolation=None)\n",
    "    for x in range(10, 90, 10):\n",
    "        ax.axvline(x, color=\"w\", linewidth=0.5)\n",
    "        ax.axhline(x, color=\"w\", linewidth=0.5)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "fig.colorbar(img, ax=axes, location=\"bottom\", shrink=0.3, aspect=10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e2c25-c0b2-4e07-b7ff-fbeba3354b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{unit_name}_motif_distances_training.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4026cb-55f8-4578-a0ca-c47dcb3b05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_discrim = (1, 1)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=True, figsize=figsize_discrim, dpi=300)\n",
    "for ax, bkgnd_level in zip(axes, bkgnd_levels):\n",
    "    spike_dists = pairwise_spike_comparison(spike_trains.loc[bkgnd_level], comparison_fun=inv_spike_sync_matrix, stack=False)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=\"precomputed\")\n",
    "    loo = ShuffledLeaveOneOut(rng)\n",
    "    group_idx, names = spike_dists.index.factorize()\n",
    "    pred = cross_val_predict(neigh, spike_dists.values, group_idx, cv=loo)\n",
    "    conf_mtx = confusion_matrix(group_idx, pred, normalize=\"true\")    \n",
    "    img = ax.imshow(conf_mtx, origin=\"upper\", aspect=\"equal\", vmin=0, vmax=1.0)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_title(f\"{bkgnd_level} dB\", fontdict={\"fontsize\": 6})\n",
    "fig.colorbar(img, ax=axes, location=\"bottom\", shrink=0.4, aspect=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2cc89-e5a4-405d-bdad-7badf0426536",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{unit_name}_motif_discrim_training.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd361a12-f665-472a-bd10-f164eb010015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions from the training\n",
    "pred_training = pd.concat([pd.Series(names[pred], index=spike_dists.index).rename_axis(\"foreground\").rename(\"predicted\")], keys=[-100], names=[\"background-dBFS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc16b5-b6a9-439d-b981-bddde7c134e3",
   "metadata": {},
   "source": [
    "## Invariance\n",
    "\n",
    "In this approach, we fit the classifier to the clean data and then see how accurately it classifies responses to the noisy stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d2e66-775e-448b-a590-b8c713607737",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_train = spike_trains.loc[-100]\n",
    "train = pairwise_spike_comparison(st_train, comparison_fun=inv_spike_sync_matrix, stack=False)\n",
    "neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=\"precomputed\")\n",
    "group_idx, names = train.index.factorize()\n",
    "neigh.fit(train.values, group_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1805a297-8a17-43b4-89b9-71ecb9361ce4",
   "metadata": {},
   "source": [
    "For each trial not in the training set, calculate the spike distance to all the trials in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0579e-f8b0-43f0-b4a0-87ca07a14ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_training(st_test):\n",
    "    return st_train.apply(lambda st_ref: 1 - pyspike.spike_sync(st_ref, st_test.spikes)).rename_axis(\"ref\")\n",
    "dist_to_clean = spike_trains.drop(-100).to_frame(\"spikes\").apply(compare_to_training, axis=1)\n",
    "predicted = pd.Series(names[neigh.predict(dist_to_clean.values)], index=dist_to_clean.index).rename(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679009b-a25a-43a1-95ca-fd0fc8c1bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkgnd_levels = (-60, -25)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=figsize_distances, dpi=400)\n",
    "for ax, bkgnd_level in zip(axes, bkgnd_levels):\n",
    "    dist = dist_to_clean.loc[bkgnd_level]\n",
    "    img = ax.imshow(1 - dist, vmin=0, vmax=1, aspect=\"equal\", origin=\"upper\", interpolation=None)\n",
    "    for x in range(10, 90, 10):\n",
    "        ax.axvline(x, color=\"w\", linewidth=0.3)\n",
    "        ax.axhline(x, color=\"w\", linewidth=0.3)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "fig.colorbar(img, ax=axes, location=\"bottom\", shrink=0.3, aspect=10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7639f1-9532-44a0-ab7d-4299c1026e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{unit_name}_motif_distances_testing.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc01c9-282a-4ede-8fe6-f4812d405773",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=True, figsize=figsize_discrim, dpi=300)\n",
    "for ax, bkgnd_level in zip(axes, bkgnd_levels):\n",
    "    pred = predicted.loc[bkgnd_level].reset_index()\n",
    "    conf_mtx = confusion_matrix(pred[\"foreground\"].values, pred[\"predicted\"].values, normalize=\"true\")\n",
    "    img = ax.imshow(conf_mtx, origin=\"upper\", aspect=\"equal\", vmin=0, vmax=1.0)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_title(f\"{bkgnd_level} dB\", fontdict={\"fontsize\": 6})\n",
    "fig.colorbar(img, ax=axes, location=\"bottom\", shrink=0.4, aspect=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2cd325-c5b7-4f4b-b7be-3417113faf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{unit_name}_motif_discrim_testing.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7621c1-3d85-42ea-a28c-e79ef4e44dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to sub in the xvalidated accuracy for training\n",
    "acc = (\n",
    "    pd.concat([pred_training, predicted])\n",
    "    .pipe(lambda ser: pd.Series(1.0 * (ser.index.get_level_values(-1) == ser), index=ser.index))\n",
    "    .rename(\"correct\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24346ce2-b91b-4837-8386-93bf4aebb900",
   "metadata": {},
   "source": [
    "This panel has to be hand-edited to add a gap between 70 and 35 dB SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae9bb2-e021-4015-9310-9159674103fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(1, 1), dpi=300)\n",
    "sns.pointplot(x=\"background-dBFS\", y=\"correct\", errorbar=\"se\", capsize=0.3, data=acc.reset_index(), ax=axes)\n",
    "levels = -30 - acc.index.unique(level=0)\n",
    "idx_keep = [0] + list(range(1, levels.size, 2))\n",
    "axes.axhline(1/9, color=\"k\", linestyle=\":\")\n",
    "axes.set_xticks(idx_keep, levels[idx_keep])\n",
    "axes.set_xlabel(\"SNR (dB)\")\n",
    "axes.set_ylabel(\"p(correct)\")\n",
    "axes.set_ylim(0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fae865-9335-4f92-a896-cc7df2290597",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"../figures/{unit_name}_motif_discrim_summary.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbab7c-2e06-4eb3-b3ad-430d6e0c8f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noise-invariant-analysis",
   "language": "python",
   "name": "noise-invariant-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
